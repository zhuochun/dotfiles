#!/usr/bin/env ruby
# encoding: utf-8

# Query and answer questions based on an index file
#
# Usage: ai-rag-query index-file "qn"
# Usage: ai-rag-query index-file "qn" -gpt
# Usage: ai-rag-query index-file "qn" -qn
# Usage: ai-rag-query index-file "qn" -server
#
# Requires OpenAI API Key stored in DOT_OPENAI_KEY

require_relative "../scripts/utils-ai"

OPT_SERVER = ARGV.delete('-server') # run as a server instead of cmd, open http://localhost:4567/q.html

OPT_GPT = ARGV.delete('-gpt') # use openai's embedding
OPT_QN = ARGV.delete('-qn') # question mode, if not specified, return the top 10 similar refs instead

if OPT_GPT || OPT_QN
    OPENAI_KEY = ENV["DOT_OPENAI_KEY"] || ""
    if OPENAI_KEY.empty?
        STDOUT << "Remember to set env DOT_OPENAI_KEY\n"
        exit 9
    end
end

if OPT_SERVER
    if ARGV.length != 1
        STDOUT << "Expect index-file in argument\n"
        exit 1
    end
else
    if ARGV.length != 2
        STDOUT << "Expect index-file and query in arguments\n"
        exit 1
    end
end

def file_content(file)
    content = ""

    File.foreach(file) do |line|
        if line.start_with?(/- .+:/) || line.start_with?('  - [[') # yaml like
            next
        elsif line.start_with?('<') # html like
            next
        else
            content << line unless line.strip.empty?
        end
    end

    content
end

def retrieve(q, topN)
    qe = if OPT_GPT then embedding(q) else embedding_ollama(q) end

    ans = []
    File.foreach(ARGV[0]) do |line|
        item = JSON.parse(line)

        score = cosine_similarity(qe, item["embedding"])
        next unless OPT_GPT || score >= 0.5 # min threshold for ollama

        item["score"] = score
        ans << item
    end

    ans = ans.sort_by { |a| -a["score"] }.take(topN)
    ans.each { |a| a["text"] = file_content(a["path"]) }
    ans
end

def generate(q, refs)
    messages = [
        {
            role: ROLE_SYSTEM,
            content: "You are a helpful assistent, answer the question (in the language of the question) based on the materials provided. Use a material when it is useful to the question. If all materials are not useful, reply 'Not enough materials' then answer the question based on your own knowledge."
        }
    ]

    user_msg = "materials:\n"
    refs.take(5).each_with_index do |a, idx|
        user_msg << "<MATERIAL #{idx}>#{file_content(a['path'])}</MATERIAL #{idx}>\n"
    end

    user_msg << "question: #{ARGV[1]}\nanswer:\n"

    messages << { role: ROLE_USER, content: user_msg }
    chat(messages)
end

def rag(q, needAns)
    resp = {}

    refs = retrieve(q, 10)
    resp["refs"] = refs

    if refs.length == 0
        resp["error"] = "Nothing found"
        return resp
    end

    resp["ans"] = generate(q, refs) if needAns

    return resp
end

if OPT_SERVER
    require 'sinatra' # gem install sinatra

    set :lock, true

    post '/q' do
        content_type :json

        data = JSON.parse(request.body.read)

        resp = rag(data["q"], data["qn"])
        resp.to_json
    end

else

    res_data = rag(ARGV[1], OPT_QN)

    if res_data["error"]
        STDOUT << "ERROR: #{res_data["error"]}"
        exit 9
    end

    STDOUT << "REPLY: #{res_data["ans"]}\n" if OPT_QN

    res_data["refs"].each_with_index do |a, idx|
        STDOUT << "=== FILE (#{idx}): #{a["path"]}, Score: #{a["score"]}\n"
        STDOUT << "#{a["text"]}\n"
    end

end
