#!/usr/bin/env ruby
# encoding: utf-8

# Use two conversations and one editor
#
# Usage: ai-conv p1.txt p2.txt p3.txt 3
#
# Requires OpenAI API Key stored in DOT_OPENAI_KEY

require "net/http"
require "json"

OPENAI_KEY = ENV["DOT_OPENAI_KEY"] || ""
if OPENAI_KEY.empty?
  STDOUT << "Remember to set env DOT_OPENAI_KEY\n"
  exit 9
end

MODE_SEPARATOR = "###### "
ROLE_SYSTEM = "system"
ROLE_USER = "user"
ROLE_ASSISTANT = "assistant"
NEXT_ROLE = ->(role) { role != ROLE_USER ? ROLE_USER : ROLE_ASSISTANT }

if ARGV.length != 4
  STDOUT << "Invalid arguments received\n"
  exit 1
end

def check_path(prompt_path)
  if prompt_path.empty? || !File.exist?(prompt_path)
    STDOUT << "File path not found #{prompt_path}\n"
    exit 1
  end
end

p1_file = ARGV[0]
p2_file = ARGV[1]
ww_file = ARGV[2]

check_path(p1_file)
check_path(p2_file)
check_path(ww_file)

num_round = ARGV[3].to_i # how many round of discussions

def open_file(prompt_path)
  role = ROLE_SYSTEM # starts with system setup
  messages = []

  File.open(prompt_path, "r") do |file|
    content = []

    file.each_line do |line|
      line.strip!

      if line.start_with?(MODE_SEPARATOR)
        messages << { "role": role, "content": content.join(" ") }

        next_role = line.split(MODE_SEPARATOR)[1].strip
        # small auto fix when multiple prompt
        if role == next_role
          # we don't start a new one, automatically continue the msg
        else
          content = [] # reset
          role = NEXT_ROLE.call(role)
        end
      else
        content << line unless line.empty?
      end
    end

    messages << { "role": role, "content": content.join(" ") } unless content.empty?
  end

  if messages.empty? || role == ROLE_ASSISTANT # must have a message and end with a user message
    STDOUT << "No prompt message at the end: #{prompt_path}\n"
    exit 1
  end

  STDOUT << "Chat: #{prompt_path}. Messages: #{messages.length}\n"
  messages
end

def append_file(prompt_path, role, msg)
  File.open(prompt_path, "a") do |file|
    file.puts("\n#{MODE_SEPARATOR} #{role}")
    file.puts("\n#{msg}")
  end
end

def chat(messages)
  url = URI("https://api.openai.com/v1/chat/completions")
  headers = {
    "Content-Type" => "application/json",
    "Authorization" => "Bearer #{OPENAI_KEY}"
  }

  data = {
    "model" => "gpt-3.5-turbo-16k",
    "messages" => messages
  }

  http = Net::HTTP.new(url.host, url.port)
  http.use_ssl = true

  request = Net::HTTP::Post.new(url, headers)
  request.body = data.to_json

  response = http.request(request)

  if response.code != "200"
    STDOUT << "Chat error: #{response}\n"
    exit 1
  end

  result = JSON.parse(response.body)
  result["choices"][0]["message"]["content"]
end

num_round.times do |i|
  STDOUT << "=== Start conv #{i}: P1 chat\n"

  p1_msg = open_file(p1_file)
  p1_resp = chat(p1_msg)

  append_file(p1_file, ROLE_ASSISTANT, p1_resp)
  append_file(p2_file, ROLE_USER, p1_resp) # let p2 to pick up

  STDOUT << "Start conv #{i}: P2 chat\n"

  p2_msg = open_file(p2_file)
  p2_resp = chat(p2_msg)

  append_file(p2_file, ROLE_ASSISTANT, p2_resp)
  append_file(p1_file, ROLE_USER, p2_resp) # let p1 to pick up

  STDOUT << "Start conv #{i}: WW chat\n"

  append_file(ww_file, ROLE_USER, p1_resp + "\n\n" + p2_resp) # let ww to pick up

  STDOUT << "=== End this conv #{i}\n"
end

ww_msg = open_file(ww_file)
ww_resp = chat(ww_msg)
append_file(ww_file, ROLE_ASSISTANT, ww_resp)